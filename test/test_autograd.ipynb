{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0101e1e8",
   "metadata": {},
   "source": [
    "### 获取根路径\n",
    "* 方便测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a956f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 获取当前工作目录\n",
    "# Trytorch\\test\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# 获取父目录\n",
    "# Trytorch\n",
    "project_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# 现在的路径即为项目根路径,可以找到主包trytorch\n",
    "sys.path.append(project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094d27ac",
   "metadata": {},
   "source": [
    "### 构建简单计算图验证正向功能\n",
    "<img src=\"../figures/graph.png\" alt=\"compute_graph\" style=\"width:100%; height:auto;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e03493b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------grads--------------------\n",
      "v4.grad: tensor(1.0, dtpye=float64)\n",
      "v3.grad: tensor(2.718281828459045, dtpye=float64)\n",
      "v2.grad: tensor(6.43656365691809, dtpye=float64)\n",
      "v1.grad: tensor(17.496394026320345, dtpye=float64)\n"
     ]
    }
   ],
   "source": [
    "import trytorch as torch\n",
    "from trytorch import ops\n",
    "\n",
    "# 前向计算\n",
    "val = 1\n",
    "\n",
    "v1 = torch.Tensor(val, device=None,dtype=int)\n",
    "v2 = ops.exp(v1)\n",
    "v3 = v2 + 1\n",
    "v4 = v2 * v3\n",
    "y = v4\n",
    "\n",
    "# 反向传播\n",
    "y.backward()\n",
    "\n",
    "print()\n",
    "print(\"----------------------grads--------------------\")\n",
    "print(\"v4.grad:\", v4.grad)  # dy/dv4 = 1\n",
    "print(\"v3.grad:\", v3.grad)  # dy/dv3\n",
    "print(\"v2.grad:\", v2.grad)  # dy/dv2\n",
    "print(\"v1.grad:\", v1.grad)  # dy/dv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a9ee3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: tensor(10.1073, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "---------------grads---------------\n",
      "v4.grad: tensor(1., dtype=torch.float64)\n",
      "v3.grad: tensor(2.7183, dtype=torch.float64)\n",
      "v2.grad: tensor(6.4366, dtype=torch.float64)\n",
      "v1.grad: tensor(17.4964, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "### pytorch 代码\n",
    "import torch as pytorch\n",
    "val = 1\n",
    "\n",
    "# 前向\n",
    "v1 = pytorch.tensor(val, device=None,dtype=float,requires_grad=True)\n",
    "v2 = pytorch.exp(v1)\n",
    "v3 = v2 + 1\n",
    "v4 = v2 * v3\n",
    "y = v4\n",
    "print(\"y:\", y)\n",
    "\n",
    "# 反向\n",
    "# 保留中间变量的梯度\n",
    "v2.retain_grad()\n",
    "v3.retain_grad()\n",
    "v4.retain_grad()\n",
    "y.backward()\n",
    "\n",
    "print(\"---------------grads---------------\")\n",
    "print(\"v4.grad:\", v4.grad)  # dy/dv4 = 1\n",
    "print(\"v3.grad:\", v3.grad)  # dy/dv3\n",
    "print(\"v2.grad:\", v2.grad)  # dy/dv2\n",
    "print(\"v1.grad:\", v1.grad)  # dy/dv1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcd8e0d",
   "metadata": {},
   "source": [
    "### 最终验证\n",
    "<img src=\"../figures/backward.png\" alt=\"backward\" style=\"width:55%; height:auto;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de9ed93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------grads---------------------------\n",
      "v7: tensor(1.0, dtpye=float64)\n",
      "v6: tensor(1.0, dtpye=float64)\n",
      "v5: tensor(-1.0, dtpye=float64)\n",
      "v4: tensor(1.0, dtpye=float64)\n",
      "v3: tensor(1.0, dtpye=float64)\n",
      "v2: tensor(1.8, dtpye=float64)\n",
      "v1: tensor(5.5, dtpye=float64)\n"
     ]
    }
   ],
   "source": [
    "x1 = 2\n",
    "x2 = 5\n",
    "\n",
    "v1 = torch.Tensor(x1, device=None,dtype=float)\n",
    "v2 = torch.Tensor(x2, device=None,dtype=float)\n",
    "v3 = ops.log(v1) #log\n",
    "v4 = v1 * v2\n",
    "v5 = ops.log(v2) #sin\n",
    "v6 = v3 + v4\n",
    "v7 = v6 - v5 # 目前这里被算了两次\n",
    "\n",
    "v7.backward()\n",
    "\n",
    "print(\"-------------------------------grads---------------------------\")\n",
    "\n",
    "print(\"v7:\", v7.grad) ; print(\"v6:\", v6.grad) ;print(\"v5:\", v5.grad) ; print(\"v4:\", v4.grad) ; print(\"v3:\", v3.grad) ; print(\"v2:\", v2.grad) ; print(\"v1:\", v1.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c3679e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------grads---------------------------\n",
      "v7: tensor(1., dtype=torch.float64)\n",
      "v6: tensor(1., dtype=torch.float64)\n",
      "v5: tensor(-1., dtype=torch.float64)\n",
      "v4: tensor(1., dtype=torch.float64)\n",
      "v3: tensor(1., dtype=torch.float64)\n",
      "v2: tensor(1.8000, dtype=torch.float64)\n",
      "v1: tensor(5.5000, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# pytorch验证\n",
    "x1 = 2\n",
    "x2 = 5\n",
    "\n",
    "v1 = pytorch.tensor(x1, device=None,dtype=float,requires_grad=True)\n",
    "v2 = pytorch.tensor(x2, device=None,dtype=float,requires_grad=True)\n",
    "v3 = pytorch.log(v1) #log\n",
    "v4 = v1 * v2\n",
    "v5 = pytorch.log(v2) #sin\n",
    "v6 = v3 + v4\n",
    "v7 = v6 - v5 \n",
    "\n",
    "v1.retain_grad()\n",
    "v2.retain_grad()\n",
    "v3.retain_grad()\n",
    "v4.retain_grad()\n",
    "v5.retain_grad()\n",
    "v6.retain_grad()\n",
    "v7.retain_grad()\n",
    "\n",
    "v7.backward()\n",
    "\n",
    "print(\"-------------------------------grads---------------------------\")\n",
    "\n",
    "print(\"v7:\", v7.grad)\n",
    "print(\"v6:\", v6.grad)\n",
    "print(\"v5:\", v5.grad)\n",
    "print(\"v4:\", v4.grad)\n",
    "print(\"v3:\", v3.grad)\n",
    "print(\"v2:\", v2.grad)\n",
    "print(\"v1:\", v1.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4df62a",
   "metadata": {},
   "source": [
    "### 最终测试,使用单元测试工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc6368ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.9.0, pytest-7.4.3, pluggy-1.3.0 -- c:\\users\\gamedesign\\appdata\\local\\programs\\python\\python39\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: d:\\AIExperienments\\TryTorch\\test\n",
      "plugins: anyio-3.7.1\n",
      "collecting ... collected 19 items\n",
      "\n",
      "test_autograd.py::test_divide_forward PASSED                             [  5%]\n",
      "test_autograd.py::test_divide_scalar_forward PASSED                      [ 10%]\n",
      "test_autograd.py::test_matmul_forward PASSED                             [ 15%]\n",
      "test_autograd.py::test_summation_forward PASSED                          [ 21%]\n",
      "test_autograd.py::test_broadcast_to_forward PASSED                       [ 26%]\n",
      "test_autograd.py::test_reshape_forward PASSED                            [ 31%]\n",
      "test_autograd.py::test_negate_forward PASSED                             [ 36%]\n",
      "test_autograd.py::test_transpose_forward PASSED                          [ 42%]\n",
      "test_autograd.py::test_divide_backward PASSED                            [ 47%]\n",
      "test_autograd.py::test_divide_scalar_backward PASSED                     [ 52%]\n",
      "test_autograd.py::test_matmul_simple_backward PASSED                     [ 57%]\n",
      "test_autograd.py::test_matmul_batched_backward PASSED                    [ 63%]\n",
      "test_autograd.py::test_reshape_backward PASSED                           [ 68%]\n",
      "test_autograd.py::test_negate_backward PASSED                            [ 73%]\n",
      "test_autograd.py::test_transpose_backward PASSED                         [ 78%]\n",
      "test_autograd.py::test_broadcast_to_backward PASSED                      [ 84%]\n",
      "test_autograd.py::test_summation_backward PASSED                         [ 89%]\n",
      "test_autograd.py::test_topo_sort PASSED                                  [ 94%]\n",
      "test_autograd.py::test_compute_gradient PASSED                           [100%]\n",
      "\n",
      "============================== warnings summary ===============================\n",
      "c:\\users\\gamedesign\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\__init__.py:146\n",
      "  c:\\users\\gamedesign\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "    warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "\n",
      "c:\\users\\gamedesign\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\cupy\\_environment.py:215\n",
      "  c:\\users\\gamedesign\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\cupy\\_environment.py:215: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "    warnings.warn(\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "======================= 19 passed, 2 warnings in 1.18s ========================\n"
     ]
    }
   ],
   "source": [
    "! pytest test_autograd.py -v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
