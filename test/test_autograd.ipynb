{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0101e1e8",
   "metadata": {},
   "source": [
    "### 获取根路径\n",
    "* 方便测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a956f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 获取当前工作目录\n",
    "# Trytorch\\test\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# 获取父目录\n",
    "# Trytorch\n",
    "project_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# 现在的路径即为项目根路径,可以找到主包trytorch\n",
    "sys.path.append(project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094d27ac",
   "metadata": {},
   "source": [
    "### 构建简单计算图验证正向功能\n",
    "<img src=\"../figures/graph.png\" alt=\"compute_graph\" style=\"width:100%; height:auto;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e03493b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: tensor(1, dtpye=int32)\n",
      "v2: tensor(2.718281828459045, dtpye=float64)\n",
      "v3: tensor(3.718281828459045, dtpye=float64)\n",
      "v4: tensor(10.107337927389695, dtpye=float64)\n",
      "y: tensor(10.107337927389695, dtpye=float64)\n",
      "\n",
      "----------------------grads--------------------\n",
      "v4.grad: tensor(1.0, dtpye=float64)\n",
      "v3.grad: tensor(2.718281828459045, dtpye=float64)\n",
      "v2.grad: tensor(6.43656365691809, dtpye=float64)\n",
      "v1.grad: tensor(17.496394026320345, dtpye=float64)\n"
     ]
    }
   ],
   "source": [
    "import trytorch as torch\n",
    "from trytorch import ops as F\n",
    "\n",
    "# 前向计算\n",
    "val = 1\n",
    "\n",
    "v1 = torch.Tensor(val, device=None,dtype=int)\n",
    "v2 = F.exp(v1)\n",
    "v3 = v2 + 1\n",
    "v4 = v2 * v3\n",
    "y = v4\n",
    "\n",
    "print(\"v1:\", v1)\n",
    "print(\"v2:\", v2)\n",
    "print(\"v3:\", v3)\n",
    "print(\"v4:\", v4)\n",
    "print(\"y:\", y)\n",
    "\n",
    "# 反向传播\n",
    "y.backward()\n",
    "\n",
    "print()\n",
    "print(\"----------------------grads--------------------\")\n",
    "print(\"v4.grad:\", v4.grad)  # dy/dv4 = 1\n",
    "print(\"v3.grad:\", v3.grad)  # dy/dv3\n",
    "print(\"v2.grad:\", v2.grad)  # dy/dv2\n",
    "print(\"v1.grad:\", v1.grad)  # dy/dv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9ee3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: tensor(10.1073, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "---------------grads---------------\n",
      "v4.grad: tensor(1., dtype=torch.float64)\n",
      "v3.grad: tensor(2.7183, dtype=torch.float64)\n",
      "v2.grad: tensor(6.4366, dtype=torch.float64)\n",
      "v1.grad: tensor(17.4964, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "### pytorch 代码\n",
    "import torch as pytorch\n",
    "val = 1\n",
    "\n",
    "# 前向\n",
    "v1 = pytorch.tensor(val, device=None,dtype=float,requires_grad=True)\n",
    "v2 = pytorch.exp(v1)\n",
    "v3 = v2 + 1\n",
    "v4 = v2 * v3\n",
    "y = v4\n",
    "print(\"y:\", y)\n",
    "\n",
    "# 反向\n",
    "# 保留中间变量的梯度\n",
    "v2.retain_grad()\n",
    "v3.retain_grad()\n",
    "v4.retain_grad()\n",
    "y.backward()\n",
    "\n",
    "print(\"---------------grads---------------\")\n",
    "print(\"v4.grad:\", v4.grad)  # dy/dv4 = 1\n",
    "print(\"v3.grad:\", v3.grad)  # dy/dv3\n",
    "print(\"v2.grad:\", v2.grad)  # dy/dv2\n",
    "print(\"v1.grad:\", v1.grad)  # dy/dv1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcd8e0d",
   "metadata": {},
   "source": [
    "### 最终验证\n",
    "<img src=\"../figures/backward.png\" alt=\"backward\" style=\"width:40%; height:auto;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de9ed93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1: 2\n",
      "x2: 5\n",
      "v1: tensor(2, dtpye=int32)\n",
      "v2: tensor(5, dtpye=int32)\n",
      "v3: tensor(0.6931471805599453, dtpye=float64)\n",
      "v4: tensor(10, dtpye=int32)\n",
      "v5: tensor(-0.9589242746631385, dtpye=float64)\n",
      "v6: tensor(10.693147180559945, dtpye=float64)\n",
      "v7: tensor(9.734222905896807, dtpye=float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(2, dtpye=int32),\n",
       " tensor(0.6931471805599453, dtpye=float64),\n",
       " tensor(5, dtpye=int32),\n",
       " tensor(10, dtpye=int32),\n",
       " tensor(10.693147180559945, dtpye=float64),\n",
       " tensor(-0.9589242746631385, dtpye=float64),\n",
       " tensor(9.734222905896807, dtpye=float64)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = 2\n",
    "x2 = 5\n",
    "\n",
    "v1 = torch.Tensor(x1, device=None,dtype=int)\n",
    "v2 = torch.Tensor(x2, device=None,dtype=int)\n",
    "v3 = F.log(v1)\n",
    "v4 = v1 * v2\n",
    "v5 = F.sin(v2)\n",
    "v6 = v3 + v4\n",
    "v7 = v6 - v5 # 目前这里被算了两次\n",
    "\n",
    "\n",
    "print(\"x1:\", x1)\n",
    "print(\"x2:\", x2)\n",
    "print(\"v1:\", v1)\n",
    "print(\"v2:\", v2)\n",
    "print(\"v3:\", v3)\n",
    "print(\"v4:\", v4)\n",
    "print(\"v5:\", v5)\n",
    "print(\"v6:\", v6)\n",
    "print(\"v7:\", v7)\n",
    "\n",
    "v7.topo_order()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
