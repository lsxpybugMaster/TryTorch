{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13d1993",
   "metadata": {},
   "source": [
    "### 获取根路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1339a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 获取当前工作目录\n",
    "# Trytorch\\test\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# 获取父目录\n",
    "# Trytorch\n",
    "project_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# 现在的路径即为项目根路径,可以找到主包trytorch\n",
    "sys.path.append(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "541d9349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GameDesign\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\cupy\\_environment.py:215: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import trytorch as torch\n",
    "import trytorch.ops as ops\n",
    "import trytorch.nn as nn\n",
    "import trytorch.optim as optim\n",
    "import trytorch.datas as data\n",
    "from trytorch.array_device import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621121b4",
   "metadata": {},
   "source": [
    "### 搭建网络,优化器,损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c5754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 10\n",
    "device = cpu()\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, hidden = 100 , device = device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(784, hidden, device=device),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, 10, device=device),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "net = Model()\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.001,weight_decay=0.001)\n",
    "criterion = nn.SoftmaxLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7633f34",
   "metadata": {},
   "source": [
    "### 如果测试池化层,则执行该模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94eb00cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "epochs = 3\n",
    "device = cpu()\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, device=None, dtype=\"float32\"):\n",
    "        super().__init__()\n",
    "        # (N, 1, 28, 28) -> (N, 6, 28, 28)\n",
    "        self.conv1 = nn.Conv(in_channels=1,out_channels=6, kernel_size=5, stride=1, device=device, dtype=dtype)  # (N, 6, 28, 28)\n",
    "        self.pool1 = nn.MaxPooling2D(kernel_size=2, stride=2, device=device, dtype=dtype)  # (N, 6, 14, 14)\n",
    "        \n",
    "        self.conv2 = nn.Conv(6, 16,kernel_size=5, stride=1, device=device, dtype=dtype)  # (N, 16, 14, 14)\n",
    "        self.pool2 = nn.MaxPooling2D(kernel_size=2, stride=2, device=device, dtype=dtype)  # (N, 16, 7, 7)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, 120, device=device, dtype=dtype)\n",
    "        self.fc2 = nn.Linear(120, 84, device=device, dtype=dtype)\n",
    "        self.fc3 = nn.Linear(84, 10, device=device, dtype=dtype)  # 10类分类\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)  \n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)   \n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = LeNet5()\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.001,weight_decay=0.001)\n",
    "criterion = nn.SoftmaxLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043dea98",
   "metadata": {},
   "source": [
    "### dataset 与 dataloader 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b470f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\AIExperienments\\TryTorch\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "project_path = Path(project_dir)\n",
    "print(project_path)\n",
    "\n",
    "# 训练数据集\n",
    "train_dataset = data.MNISTDataset(\n",
    "    project_path / \"data\" / \"MNIST\" / \"train-images-idx3-ubyte.gz\",\n",
    "    project_path / \"data\" / \"MNIST\" / \"train-labels-idx1-ubyte.gz\"\n",
    ")\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataset = data.MNISTDataset(\n",
    "    project_path / \"data\" / \"MNIST\" / \"t10k-images-idx3-ubyte.gz\",\n",
    "    project_path / \"data\" / \"MNIST\" / \"t10k-labels-idx1-ubyte.gz\"\n",
    ")\n",
    "\n",
    "test_dataloader = data.DataLoader(\n",
    "    dataset = test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07744979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 显示数据集\n",
    "\n",
    "img, label = train_dataset[42]\n",
    "# 因为是 (1, 28, 28)，需要 squeeze 去掉 channel 维度\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# 显示数据加载器\n",
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb642c40",
   "metadata": {},
   "source": [
    "### 🤗 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1f373f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   0%|          | 0/300 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 300/300 [02:30<00:00,  1.99batch/s, loss=0.3057, acc=0.9070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0: avg_accuracy=0.9069666666666667, avg_loss=0.30573671423594173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 300/300 [02:30<00:00,  1.99batch/s, loss=0.1094, acc=0.9665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1: avg_accuracy=0.9665166666666667, avg_loss=0.10943053931395225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 300/300 [02:34<00:00,  1.95batch/s, loss=0.0775, acc=0.9764]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2: avg_accuracy=0.9764, avg_loss=0.07753533507188154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    total_rights = 0\n",
    "    total_examples = 0\n",
    "    total_batches = 0\n",
    "\n",
    "    train_bar = tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{epochs}', unit='batch')\n",
    "\n",
    "    for inputs, label in train_bar:\n",
    "        \n",
    "        net.train()\n",
    "        \n",
    "        optimizer.reset_grad()\n",
    "\n",
    "        pred = net(inputs)\n",
    "\n",
    "        loss = criterion(pred, label)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        # (batch, features) -> (batch, 1)\n",
    "        label_pred = np.argmax(pred.numpy(), axis = 1)\n",
    "\n",
    "        rights = np.equal(label_pred, label.numpy()).sum()\n",
    "\n",
    "        total_loss += loss.numpy()\n",
    "        total_rights += rights\n",
    "        total_batches += 1\n",
    "        total_examples += inputs.shape[0]\n",
    "\n",
    "        # 实时更新进度条信息\n",
    "        avg_loss_so_far = total_loss / total_batches\n",
    "        avg_accuracy_so_far = total_rights / total_examples\n",
    "        \n",
    "        # 更新进度条描述\n",
    "        train_bar.set_postfix({\n",
    "            'loss': f'{avg_loss_so_far:.4f}',\n",
    "            'acc': f'{avg_accuracy_so_far:.4f}'\n",
    "        })\n",
    "\n",
    "    avg_loss = total_loss / total_batches\n",
    "    avg_accuracy = total_rights / total_examples\n",
    "    print(f\"EPOCH {epoch}: {avg_accuracy=}, {avg_loss=}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5014ab",
   "metadata": {},
   "source": [
    "### 🤗 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2b1ad49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SCORE: avg_accuracy=0.9802, avg_loss=0.06294495978355409\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "total_rights = 0\n",
    "total_examples = 0\n",
    "total_batches = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, label in test_dataloader:\n",
    "        \n",
    "        net.eval()\n",
    "\n",
    "        pred = net(inputs)\n",
    "\n",
    "        loss = criterion(pred, label)\n",
    "\n",
    "        label_pred = np.argmax(pred.numpy(),axis=1)\n",
    "        \n",
    "        rights = np.equal(label_pred, label.numpy()).sum()\n",
    "\n",
    "        total_loss += loss.numpy()\n",
    "        total_rights += rights\n",
    "        total_batches += 1\n",
    "        total_examples += inputs.shape[0]\n",
    "\n",
    "    avg_loss = total_loss / total_batches\n",
    "    avg_accuracy = total_rights / total_examples\n",
    "    print(f\"TEST SCORE: {avg_accuracy=}, {avg_loss=}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
